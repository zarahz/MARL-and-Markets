{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import os\n",
    "from prettytable import PrettyTable\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all storage folders to extract training info, i.e. markets and save it to envs\n",
    "#TODO normalize rewards to \"reward_summary\"\n",
    "df_keys = [\"reward_summary\", \"mean_grid_coloration_percentage\", \"mean_num_reset_fields\", \"fully_colored\", \"mean_num_frames_per_episode\", \"mean_trades\"]\n",
    "\n",
    "try:\n",
    "    training_folders = os.listdir('.') \n",
    "except(FileNotFoundError):\n",
    "    training_folders = []\n",
    "\n",
    "# while iterating create a wideform dataframe of all csv files\n",
    "df_settings_dict = {}\n",
    "\n",
    "for folder in training_folders:\n",
    "    # if \"plot_results\" in folder or \"dqn_comparisons\" in folder:\n",
    "    #     continue\n",
    "\n",
    "    # read csv file (if it exists)\n",
    "    try:\n",
    "        df_settings_dict[folder] = pd.read_csv('./'+folder+'/log.csv')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # only extract columns that are substrings of df_keys (only those are of interest here) \n",
    "    cols_of_interest = [col for col in df_settings_dict[folder].columns if any(df_key in col for df_key in df_keys) or \"frames\" in col or \"reward\" in col]\n",
    "    df_settings_dict[folder] = df_settings_dict[folder].filter(items = cols_of_interest)  \n",
    "    # add setting to the df columns\n",
    "    df_settings_dict[folder].columns = [folder + \"_\" + str(col) for col in df_settings_dict[folder].columns if any(df_key in col for df_key in df_keys) or \"frames\" in col or \"reward\" in col]\n",
    "    \n",
    "# join all dataframes (one per setting)\n",
    "all_data_df = pd.concat([df for df in df_settings_dict.values()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot functions\n",
    "\n",
    "def beautify_legend(plot_name, key):\n",
    "    # beatify plot legend labels\n",
    "    _, labels = plot_name.get_legend_handles_labels()\n",
    "    for index, label in enumerate(labels):\n",
    "        # if \"-dr\" in label:\n",
    "        #     new_label = \"difference reward\"\n",
    "        # else:\n",
    "        new_label = label.split(key)[0]\n",
    "        new_label = \" \".join(new_label.split(\"_\"))\n",
    "        new_label = \" \".join(new_label.split(\"-\"))\n",
    "        labels[index] = new_label.strip()\n",
    "    plot_name.legend(handles=plot_name.legend_.legendHandles,labels=labels)\n",
    "\n",
    "def normalize_rewards(setting_names):\n",
    "    df = all_data_df.copy()\n",
    "    for setting in setting_names:\n",
    "        reward_cols = [col for col in df.columns if setting == col.split(\"_\")[0] and \"mean_reward\" in col]\n",
    "        # normalize reward values!\n",
    "        new_col = setting+\"_reward_summary\"\n",
    "        df[new_col] = df[reward_cols].sum(axis='columns')\n",
    "        col_min = df[new_col].min()\n",
    "        col_max = df[new_col].max()\n",
    "        df[new_col] = (df[new_col]-col_min)/(col_max-col_min)\n",
    "    return df\n",
    "\n",
    "def recalculate_rewards(setting_names):\n",
    "    df = all_data_df.copy()\n",
    "    for setting in setting_names:\n",
    "        reward_cols = [col for col in df.columns if setting == col.split(\"_\")[0] and \"mean_reward\" in col]\n",
    "        new_col = setting+\"_reward_summary\"\n",
    "        if \"mixed\" in setting:\n",
    "            df[new_col] = df[reward_cols].round(2).sum(axis='columns').round(2)\n",
    "        else: # coop has always the same reward across agents\n",
    "            df[new_col] = df[reward_cols].max(axis=1).round(2)\n",
    "    return df\n",
    "\n",
    "def form_data(df, stats_setting_names, key):\n",
    "    frames_col = [col for col in df.columns if any(setting == col.split(\"_\")[0] for setting in stats_setting_names) and \"frames\" in col][0]\n",
    "    data = df[[col for col in df.columns if frames_col == col or any(setting == col.split(\"_\")[0] for setting in stats_setting_names) and key in col]]\n",
    "    long_data = data.melt(id_vars=[frames_col], var_name=\"setting\")\n",
    "    long_data.rename(columns={frames_col:'frames'}, inplace=True)\n",
    "    long_data = long_data[long_data['setting'].str.contains(key, na = False)]\n",
    "    return long_data\n",
    "\n",
    "def improve_plot(plot, subplot, key, label, title, min_value=0, max_value=None, label_interval=None):\n",
    "     # beatify plot legend labels\n",
    "    beautify_legend(plot, key)\n",
    "\n",
    "    subplot.set_ylabel(label)\n",
    "    subplot.set_title(title, fontsize = 15.0)\n",
    "\n",
    "    # show every label_interval x label if set\n",
    "    if label_interval:\n",
    "        [x_label.set_visible(False) for (index,x_label) in enumerate(plot.xaxis.get_ticklabels()) if index % label_interval != 0]\n",
    "    \n",
    "    # add some space to top/bottom of last y values \n",
    "    space = 0.05 if max_value < 10 else 1\n",
    "\n",
    "    # set min/max values to be equal for better comparisons \n",
    "    if min_value < 0:\n",
    "        plot.set_ylim(bottom=min_value-space)\n",
    "    else:\n",
    "        plot.set_ylim(bottom=-space)\n",
    "        \n",
    "    if \"reward\" in key:\n",
    "        plot.set_ylim(top=1.2)\n",
    "    elif \"grid_coloration\" in key:\n",
    "        plot.set_ylim(top=1.05)\n",
    "    elif not \"trade\" in label:\n",
    "        plot.set_ylim(top=max_value+space)\n",
    "\n",
    "def create_double_multiplot (top_stats_settings, top_plot_title, worst_stats_settings, worst_plot_title):\n",
    "    top_df = recalculate_rewards(top_stats_settings)\n",
    "    worst_df = recalculate_rewards(worst_stats_settings)\n",
    "    \n",
    "    sns.set_theme()\n",
    "    max_col = 4\n",
    "    max_row = 4\n",
    "    col = 0\n",
    "    row = 0\n",
    "\n",
    "    # every key is shown in one plot (rewards are shown in two as an exception)\n",
    "    for key in df_keys:\n",
    "        if row >= max_row or (row == 0 and col == 0): \n",
    "            row = 0\n",
    "            fig = plt.figure(constrained_layout=True, figsize=(25, 23))\n",
    "            grid = plt.GridSpec(max_row, max_col, hspace=0.3)\n",
    "\n",
    "        y_label = \" \".join(key.split(\"_\"))\n",
    "\n",
    "        top_data = form_data(top_df, top_stats_settings, key)\n",
    "        worst_data = form_data(worst_df, worst_stats_settings, key)\n",
    "\n",
    "        top_hue_order = [setting+\"_\"+key for setting in top_stats_settings]\n",
    "        worst_hue_order = [setting+\"_\"+key for setting in worst_stats_settings]\n",
    "\n",
    "        min_value = top_data[\"value\"].min() if top_data[\"value\"].min() <= worst_data[\"value\"].min() else worst_data[\"value\"].min()\n",
    "        max_value = top_data[\"value\"].max() if top_data[\"value\"].max() >= worst_data[\"value\"].max() else worst_data[\"value\"].max()\n",
    "        \n",
    "        if \"reward\" in key:\n",
    "            n_entry = 5\n",
    "            t_reward_subplot = fig.add_subplot(grid[row:1, 0:2])\n",
    "            t_reward_plot = sns.barplot(data=top_data.iloc[::n_entry, :], x=\"frames\", y=\"value\", hue=\"setting\", hue_order=top_hue_order)\n",
    "            improve_plot(t_reward_plot, t_reward_subplot, key, y_label, top_plot_title, min_value=min_value, max_value=max_value, label_interval=3)\n",
    "\n",
    "            w_reward_subplot = fig.add_subplot(grid[row:1, 2:max_col])\n",
    "            w_reward_plot = sns.barplot(data=worst_data.iloc[::n_entry, :], x=\"frames\", y=\"value\", hue=\"setting\", hue_order=worst_hue_order)\n",
    "            improve_plot(w_reward_plot, w_reward_subplot, key, y_label, worst_plot_title, min_value=min_value, max_value=max_value, label_interval=3)\n",
    "\n",
    "            row += 1\n",
    "            col = 0\n",
    "\n",
    "        t_subplot = fig.add_subplot(grid[row, col])\n",
    "        t_plot = sns.lineplot(data=top_data, x=\"frames\", legend=\"brief\", y=\"value\", hue_order=top_hue_order, hue=\"setting\", linewidth=2) # style=\"setting\"\n",
    "        improve_plot(t_plot, t_subplot, key, y_label, y_label, min_value=min_value, max_value=max_value)\n",
    "        \n",
    "        w_subplot = fig.add_subplot(grid[row, col+2])\n",
    "        w_plot = sns.lineplot(data=worst_data, x=\"frames\", legend=\"brief\", y=\"value\", hue_order=worst_hue_order, hue=\"setting\", linewidth=2) # style=\"setting\"\n",
    "        improve_plot(w_plot, w_subplot, key, y_label, y_label, min_value=min_value, max_value=max_value)\n",
    "\n",
    "        col += 1\n",
    "\n",
    "        if col >= 2:\n",
    "            row += 1\n",
    "            col = 0\n",
    "\n",
    "def print_double_multiplot(stats):\n",
    "    for index, (title, settings) in enumerate(stats.items()):\n",
    "        if index % 2 != 0:\n",
    "            # skip odds, since top and worst settings are compared side by side in one go in double plot\n",
    "            continue\n",
    "        worst_title = \"Worst \" + title.split(' ', 1)[1]\n",
    "        create_double_multiplot(settings, title, stats[worst_title], worst_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats table functions\n",
    "\n",
    "def get_all_stats(setting, keys, exclude):\n",
    "    all_stats = {}\n",
    "    for col in all_data_df.columns:\n",
    "        if any(key in col for key in keys) and setting in col and not any(ignored_setting in col for ignored_setting in exclude):\n",
    "            for key in keys:\n",
    "                if key in col and setting in col:\n",
    "                    stats_key = setting+\"|\"+key\n",
    "\n",
    "                    if stats_key not in all_stats:\n",
    "                        all_stats[stats_key] = {}\n",
    "                    \n",
    "                    if \"grid_coloration\" in key:\n",
    "                        # calculate mean\n",
    "                        all_stats[stats_key][col] = all_data_df[col].mean()\n",
    "                    elif \"reward\" not in key:\n",
    "                        all_stats[stats_key][col] = sum(all_data_df[col]) #sum(all_data_df[col][all_data_df[col].notna()])\n",
    "    \n",
    "    #  agent specific calculations\n",
    "    if any(\"reward\" in key for key in keys):\n",
    "        #iterate all settings\n",
    "        for training_folder in training_folders:\n",
    "            if setting in training_folder and not any(ignored_setting in training_folder for ignored_setting in exclude):\n",
    "                reward_cols = [col for col in all_data_df.columns if training_folder == col.split(\"_\")[0] and \"mean_reward\" in col]\n",
    "                col_name = reward_cols[0].split(\"_agent\")[0]\n",
    "                if \"mixed\" in training_folder:\n",
    "                    all_stats[stats_key][col_name] = all_data_df[reward_cols].round(2).sum(axis='columns').mean()\n",
    "                else: # coop has always the same reward across agents\n",
    "                    all_stats[stats_key][col_name] = all_data_df[reward_cols].max(axis=1).mean()\n",
    "    \n",
    "    return all_stats\n",
    "\n",
    "def get_top_worst_settings(keys, setting, stats_amount=10, exclude=[]):\n",
    "    all_stats = get_all_stats(setting, keys, exclude)\n",
    "\n",
    "    results = []\n",
    "    table_headers = []\n",
    "    df_cols = {}\n",
    "    for stat, entries in all_stats.items():\n",
    "        formatted_table_header = \" \".join(stat.split(\"_\")).split(\"|\")[1]\n",
    "        top_header = \"Top \" + formatted_table_header\n",
    "        worst_header = \"Worst \" + formatted_table_header\n",
    "        if top_header not in df_cols:\n",
    "            df_cols[top_header] = [] \n",
    "        if worst_header not in df_cols:\n",
    "            df_cols[worst_header] = [] \n",
    "            \n",
    "        table_headers.append(top_header)\n",
    "        table_headers.append(worst_header)\n",
    "        # Top scores\n",
    "        top_keys = sorted(entries, key=entries.get, reverse=True)[:stats_amount]\n",
    "        results.append(top_keys)\n",
    "        results.append([all_stats[stat][top_key] for top_key in top_keys])\n",
    "        df_cols[top_header] = [top_key.split(\"_\")[0] for top_key in top_keys]\n",
    "        # Worst scores\n",
    "        worst_keys = sorted(entries, key=entries.get, reverse=False)[:stats_amount]\n",
    "        results.append(worst_keys)\n",
    "        results.append([all_stats[stat][worst_key] for worst_key in worst_keys])\n",
    "        df_cols[worst_header] = [worst_key.split(\"_\")[0] for worst_key in worst_keys]\n",
    "\n",
    "    return results, table_headers, df_cols\n",
    "\n",
    "def get_stats(*args, print_table=False):\n",
    "    stats, headers, df_cols = get_top_worst_settings(*args)\n",
    "\n",
    "    stats_table = PrettyTable(['Position'] + headers)\n",
    "    position = 1\n",
    "    \n",
    "    for row, _ in enumerate(stats[0]): # go through all entries\n",
    "        row_entries = [position]\n",
    "        # odd number contain values, even numbers contain settings\n",
    "        # stats[1] contains values\n",
    "        for column, stat in enumerate(stats):\n",
    "            if column % 2 != 0:\n",
    "                continue\n",
    "            short_key = \" \".join(stat[row].split(\"_\")[0].split(\"-\"))\n",
    "            row_entries.append(\"{:0.1f}\".format(stats[column+1][row])+\" \\n \"+ short_key + \" \\n \")\n",
    "        \n",
    "        if row_entries:\n",
    "            stats_table.add_row(row_entries)   \n",
    "            position += 1\n",
    "    \n",
    "    if print_table:\n",
    "        print(stats_table)\n",
    "    \n",
    "    return df_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if nan values occur in stats table find out what setting might be the problem here\n",
    "# print(all_data_df[all_data_df.columns[~all_data_df.isnull().any()]].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top PPO Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+---------------------+------------+--------------+\n",
      "| Position | Top fully colored | Worst fully colored | Top reward | Worst reward |\n",
      "+----------+-------------------+---------------------+------------+--------------+\n",
      "|    1     |      3072.0       |        604.0        |    0.8     |     0.7      |\n",
      "|          |       1 ppo       |        1 dqn        |   1 ppo    |    1 dqn     |\n",
      "|          |                   |                     |            |              |\n",
      "|    2     |       604.0       |       3072.0        |    0.7     |     0.8      |\n",
      "|          |       1 dqn       |        1 ppo        |   1 dqn    |    1 ppo     |\n",
      "|          |                   |                     |            |              |\n",
      "+----------+-------------------+---------------------+------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "_ = get_stats([\"reward\", \"fully_colored\"], \"1-\", 5, print_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15872/2929548266.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"reward\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fully_colored\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"2-ppo\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_table\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15872/198897386.py\u001b[0m in \u001b[0;36mget_stats\u001b[1;34m(print_table, *args)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mposition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# go through all entries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mrow_entries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# odd number contain values, even numbers contain settings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "_ = get_stats([\"reward\", \"fully_colored\"], \"2-ppo\", 5, print_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_stats = get_stats([\"fully_colored\"], \"2-ppo\", 5)\n",
    "print_double_multiplot(ppo_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top PPO Runs with restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only cooperation\n",
    "_ = get_stats([\"reward\", \"fully_colored\"], \"2-ppo\", 5, [\"mixed\", \"competitive\"], print_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only mixed\n",
    "_ = get_stats([\"reward\", \"fully_colored\"], \"2-ppo-mixed\", 5, [\"competitive\"], print_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only competitive\n",
    "_ = get_stats([\"reward\", \"fully_colored\"], \"2-ppo-mixed-competitive\", 5, [], print_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without restrictive market settings (ignoring goal, no reset and no debt settings)\n",
    "\n",
    "# pool of 10 settings remain:\n",
    "# base settings: coop, mixed, competitive   -> + 3\n",
    "# 2 markets: am, sm                         -> + 6 (for each base setting)\n",
    "# and difference rewards                    -> + 1 = 10 \n",
    "ppo_restictive_markets = get_stats([\"reward\", \"fully_colored\"], \"2-ppo\", 5, [\"goal\", \"no-reset\", \"no-debt\"], print_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_restictive_markets = get_stats([\"fully_colored\"], \"2-ppo\", 5, [\"goal\", \"no-reset\", \"no-debt\"])\n",
    "print_double_multiplot(ppo_restictive_markets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top DQN Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = get_stats([\"reward\", \"fully_colored\"], \"2-dqn\", 5, print_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_stats = get_stats([\"fully_colored\"], \"2-dqn\", 5)\n",
    "print_double_multiplot(dqn_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted DQN Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only cooperation\n",
    "_ = get_stats([\"reward\", \"fully_colored\"], \"2-dqn\", 5, [\"mixed\", \"competitive\"], print_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only mixed\n",
    "_ = get_stats([\"reward\", \"fully_colored\"], \"2-dqn-mixed\", 5, [\"competitive\"], print_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only competitive\n",
    "_ = get_stats([\"reward\", \"fully_colored\"], \"2-dqn-mixed-competitive\", 5, [], print_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = get_stats([\"reward\", \"fully_colored\"], \"2-dqn\", 5, [\"goal\", \"no-reset\", \"no-debt\"], print_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plain_dqn_stats = get_stats([\"fully_colored\"], \"2-dqn\", 5, [\"goal\", \"no-reset\", \"no-debt\"])\n",
    "# print_double_multiplot(plain_dqn_stats)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20b208b16555cc84f14c8d1edad6e351b3f4f2d7d1f9506e0ca92b98220ee842"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('Coloring-nFKiWnFj': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
